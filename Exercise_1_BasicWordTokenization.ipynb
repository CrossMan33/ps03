{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1. Basic Word Tokenization"
      ],
      "metadata": {
        "id": "NIen6y99amVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s4EC3QrYUcp",
        "outputId": "4c55e021-a9fa-4eb9-9df6-16e91db0a3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'within', 'artificial', 'intelligence', '.', 'It', 'involves', 'teaching', 'machines', 'to', 'understand', 'and', 'interpret', 'human', 'language', '.', 'NLP', 'has', 'a', 'wide', 'range', 'of', 'applications', ',', 'including', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'language', 'translation', '.', 'Understanding', 'the', 'structure', 'and', 'meaning', 'of', 'text', 'is', 'essential', 'for', 'machines', 'to', 'communicate', 'effectively', '.']\n",
            "Number of tokens: 58\n",
            "Frequency of each token:\n",
            "Natural: 1\n",
            "Language: 1\n",
            "Processing: 1\n",
            "(: 1\n",
            "NLP: 2\n",
            "): 1\n",
            "is: 2\n",
            "a: 2\n",
            "fascinating: 1\n",
            "field: 1\n",
            "within: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            ".: 4\n",
            "It: 1\n",
            "involves: 1\n",
            "teaching: 1\n",
            "machines: 2\n",
            "to: 2\n",
            "understand: 1\n",
            "and: 3\n",
            "interpret: 1\n",
            "human: 1\n",
            "language: 2\n",
            "has: 1\n",
            "wide: 1\n",
            "range: 1\n",
            "of: 2\n",
            "applications: 1\n",
            ",: 3\n",
            "including: 1\n",
            "chatbots: 1\n",
            "sentiment: 1\n",
            "analysis: 1\n",
            "translation: 1\n",
            "Understanding: 1\n",
            "the: 1\n",
            "structure: 1\n",
            "meaning: 1\n",
            "text: 1\n",
            "essential: 1\n",
            "for: 1\n",
            "communicate: 1\n",
            "effectively: 1\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Define a sample paragraph text with at least 4 sentences\n",
        "text = \"\"\"Natural Language Processing (NLP) is a fascinating field within artificial intelligence.\n",
        "It involves teaching machines to understand and interpret human language.\n",
        "NLP has a wide range of applications, including chatbots, sentiment analysis, and language translation.\n",
        "Understanding the structure and meaning of text is essential for machines to communicate effectively.\"\"\"\n",
        "\n",
        "# Tokenize the text into individual words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Display the list of tokens\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Count and display the total number of tokens\n",
        "num_tokens = len(tokens)\n",
        "print(\"Number of tokens:\", num_tokens)\n",
        "\n",
        "# Calculate and display the frequency of each token\n",
        "frequency_distribution = FreqDist(tokens)\n",
        "print(\"Frequency of each token:\")\n",
        "for token, frequency in frequency_distribution.items():\n",
        "    print(f\"{token}: {frequency}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2. Word Cloud"
      ],
      "metadata": {
        "id": "CRgMmlbParZp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5AIlUeg7awiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}